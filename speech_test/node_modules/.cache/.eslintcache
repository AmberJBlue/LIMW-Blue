[{"/Users/blue/Documents/Projects/LIMW-Blue/bridge-viz-test/src/index.js":"1","/Users/blue/Documents/Projects/LIMW-Blue/bridge-viz-test/src/App.js":"2","/Users/blue/Documents/Projects/LIMW-Blue/bridge-viz-test/src/reportWebVitals.js":"3","/Users/blue/Documents/Projects/LIMW-Blue/bridge-viz-test/src/components/Tabs.js":"4","/Users/blue/Documents/Projects/LIMW-Blue/bridge-viz-test/src/components/Tab.js":"5","/Users/blue/Documents/Projects/LIMW-Blue/bridge-viz-test/src/components/Recorder.js":"6","/Users/Work/Documents/Projects/School/SS2022/ARCH8803/LIMW-Blue/speech_test/src/index.js":"7","/Users/Work/Documents/Projects/School/SS2022/ARCH8803/LIMW-Blue/speech_test/src/reportWebVitals.js":"8","/Users/Work/Documents/Projects/School/SS2022/ARCH8803/LIMW-Blue/speech_test/src/App.js":"9","/Users/Work/Documents/Projects/School/SS2022/ARCH8803/LIMW-Blue/speech_test/src/components/Tabs.js":"10","/Users/Work/Documents/Projects/School/SS2022/ARCH8803/LIMW-Blue/speech_test/src/components/Tab.js":"11","/Users/Work/Documents/Projects/School/SS2022/ARCH8803/LIMW-Blue/speech_test/src/components/animations.js":"12"},{"size":500,"mtime":1645678127457,"results":"13","hashOfConfig":"14"},{"size":1198,"mtime":1645682818315,"results":"15","hashOfConfig":"14"},{"size":362,"mtime":1645675894887,"results":"16","hashOfConfig":"14"},{"size":1217,"mtime":1645677709896,"results":"17","hashOfConfig":"14"},{"size":729,"mtime":1645677739880,"results":"18","hashOfConfig":"14"},{"size":723,"mtime":1645682371223,"results":"19","hashOfConfig":"14"},{"size":500,"mtime":1645678127000,"results":"20","hashOfConfig":"21"},{"size":362,"mtime":1645675894000,"results":"22","hashOfConfig":"21"},{"size":1359,"mtime":1645821167407,"results":"23","hashOfConfig":"21"},{"size":1217,"mtime":1645677709000,"results":"24","hashOfConfig":"21"},{"size":729,"mtime":1645677739000,"results":"25","hashOfConfig":"21"},{"size":2559,"mtime":1645821157800,"results":"26","hashOfConfig":"21"},{"filePath":"27","messages":"28","suppressedMessages":"29","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"30"},"1oqj33a",{"filePath":"31","messages":"32","suppressedMessages":"33","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"34"},{"filePath":"35","messages":"36","suppressedMessages":"37","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"38","messages":"39","suppressedMessages":"40","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"41","messages":"42","suppressedMessages":"43","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"44","messages":"45","suppressedMessages":"46","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"47","messages":"48","suppressedMessages":"49","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"50"},"1ww0c8b",{"filePath":"51","messages":"52","suppressedMessages":"53","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"50"},{"filePath":"54","messages":"55","suppressedMessages":"56","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"57"},{"filePath":"58","messages":"59","suppressedMessages":"60","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"50"},{"filePath":"61","messages":"62","suppressedMessages":"63","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"50"},{"filePath":"64","messages":"65","suppressedMessages":"66","errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"67"},"/Users/blue/Documents/Projects/LIMW-Blue/bridge-viz-test/src/index.js",[],[],["68","69"],"/Users/blue/Documents/Projects/LIMW-Blue/bridge-viz-test/src/App.js",["70"],[],"import React from 'react';\nimport Tabs from \"./components/Tabs\";\nimport Recorder from \"./components/Recorder\"\nimport \"./App.css\";\n\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\n\n\nconst App  = () => {\n  const {\n    transcript,\n    listening,\n    resetTranscript,\n    browserSupportsSpeechRecognition\n  } = useSpeechRecognition();\n\n  if (!browserSupportsSpeechRecognition) {\n    return <span>Browser doesn't support speech recognition.</span>;\n  }\n\n  return (\n    <div>\n      <p>Microphone: {listening ? 'on' : 'off'}</p>\n      <button onClick={SpeechRecognition.startListening}>Start</button>\n      <button onClick={SpeechRecognition.stopListening}>Stop</button>\n      <button onClick={resetTranscript}>Reset</button>\n      <div>\n      <h1>Tabs Demo</h1>\n      {/* <div><Recorder></Recorder></div> */}\n      <Tabs>\n        <div label=\"Gator\">\n        <p>{transcript}</p>, <em>Alligator</em>!\n        </div>\n        <div label=\"Croc\">\n        <p>{transcript}</p>, <em>Crocodile</em>!\n        </div>\n        <div label=\"Sarcosuchus\">\n          <p>{transcript}</p> <em>extinct</em>!\n        </div>\n      </Tabs>\n    </div>\n    </div>\n  );\n};\n\nexport default App;\n","/Users/blue/Documents/Projects/LIMW-Blue/bridge-viz-test/src/reportWebVitals.js",[],[],"/Users/blue/Documents/Projects/LIMW-Blue/bridge-viz-test/src/components/Tabs.js",[],[],"/Users/blue/Documents/Projects/LIMW-Blue/bridge-viz-test/src/components/Tab.js",[],[],"/Users/blue/Documents/Projects/LIMW-Blue/bridge-viz-test/src/components/Recorder.js",[],[],"/Users/Work/Documents/Projects/School/SS2022/ARCH8803/LIMW-Blue/speech_test/src/index.js",[],[],["71","72"],"/Users/Work/Documents/Projects/School/SS2022/ARCH8803/LIMW-Blue/speech_test/src/reportWebVitals.js",[],[],"/Users/Work/Documents/Projects/School/SS2022/ARCH8803/LIMW-Blue/speech_test/src/App.js",["73"],[],"import React from 'react';\nimport Tabs from \"./components/Tabs\";\nimport { animationOne, sphere } from './components/animations';\nimport { ReactP5Wrapper } from \"react-p5-wrapper\";\nimport \"./App.css\";\n\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\nconst App  = () => {\n  const {\n    transcript,\n    listening,\n    resetTranscript,\n    browserSupportsSpeechRecognition\n  } = useSpeechRecognition();\n\n  let interim \n\n  if (!browserSupportsSpeechRecognition) {\n    return <span>Browser doesn't support speech recognition.</span>;\n  }\n\n  return (\n\n    <div>\n      <p>Microphone: {listening ? 'on' : 'off'}</p>\n      <button onClick={SpeechRecognition.startListening}>Start</button>\n      <button onClick={SpeechRecognition.stopListening}>Stop</button>\n      <button onClick={resetTranscript}>Reset</button>\n      <div>\n      <h1>Speech-to-text Demo</h1>\n      <Tabs>\n        <div label=\"Animation 1\">\n        {console.log(transcript  ? interim = transcript : interim = \"Say something positive.\")}\n        {interim.toString()}\n        <ReactP5Wrapper sketch={sphere} text={interim.toString()} />\n        </div>\n        <div label=\"Animation 2\">\n        <p>{interim}</p>\n        </div>\n        <div label=\"Animation 3\">\n          <p>{interim}</p>\n        </div>\n      </Tabs>\n    </div>\n    </div>\n  );\n};\n\nexport default App;\n","/Users/Work/Documents/Projects/School/SS2022/ARCH8803/LIMW-Blue/speech_test/src/components/Tabs.js",[],[],"/Users/Work/Documents/Projects/School/SS2022/ARCH8803/LIMW-Blue/speech_test/src/components/Tab.js",[],[],"/Users/Work/Documents/Projects/School/SS2022/ARCH8803/LIMW-Blue/speech_test/src/components/animations.js",["74","75","76","77"],[],"export function animationOne(p5) {\n    let rotation = 0;\n  \n    p5.setup = () => p5.createCanvas(600, 400, p5.WEBGL);\n  \n    p5.updateWithProps = props => {\n      if (props.rotation) {\n        rotation = (props.rotation * Math.PI) / 180;\n      }\n    };\n  \n    p5.draw = () => {\n      p5.background(100);\n      p5.normalMaterial();\n      p5.noStroke();\n      p5.push();\n      p5.rotateY(rotation);\n      p5.box(100);\n      p5.pop();\n    };\n  }\n\n  export function sphere(p5) { \n    let time = 0;\n    var img; // for the UV Grid (used to map the image to the sphere)\n\n    // Overall main output canvas size\n    let canvasWidth = 3840;\n    let canvasHeight = 2160;\n\n    // Pool dimensions\n    let poolWidth = 3072;\n    let poolHeight = 1280;\n\n    // (cameraX, cameraY, cameraZ) dictate position of the camera\n    let cameraX = 0;\n    let cameraY = 0;\n    let cameraZ = 100;\n\n    // (centerX, centerY, centerZ) dictate position the camera is pointed towards\n    let centerX = 0;\n    let centerY = 0;\n    let centerZ = 0;\n\n    let text = \"Say something positive.\"\n\n    p5.updateWithProps = props => {\n      if (props.text) {\n        text = props.text\n      }\n    };\n\n    let pg = p5.createGraphics(800, 800); // rectangle that will be mapped onto sphere\n    p5.preload = () => {\n      img = p5.loadImage('UV_Grid_Sm.jpg');\n    }\n\n    p5.setup = () => {\n      this.textBuffer = '\\n'\n      p5.createCanvas(canvasWidth, canvasHeight, p5.WEBGL);\n      \n      pg.textSize(40); // size of text\n      \n      let fov = 60.0;  // 60 degrees FOV\n       p5.perspective(p5.PI * fov / 180.0, p5.width / p5.height, 0.1, 2000);\n    }\n\n    p5.keyTyped = () => {\n      this.textBuffer += p5.key;\n    }\n\n    p5.keyPressed = () => {\n      if (p5.keyCode === p5.BACKSPACE) {\n        this.textBuffer = this.textBuffer.slice(0, -1);\n      } else if (p5.keyCode === p5.ENTER) {\n        this.textBuffer += \"\\n\";\n      }\n    }\n\n    p5.draw = () => {\n      p5.background(0);\n      \n      // set the virtual camera position\n      p5.camera(cameraX, cameraY, cameraZ, centerX, centerY, centerZ, 0, 1, 0);\n      \n      // include some light even in shadows\n      p5.ambientLight(100, 100, 100);\n      \n      let centerAxis = p5.createVector(0, 1, 0);\n      \n      //pg.background(200);\n      pg.fill(255);\n      pg.text(this.textBuffer, -4, 0);\n\n      //pass image as texture\n      p5.vtexture(pg);\n      p5.noStroke();\n      \n      p5.push();\n      p5.rotate(0.25 * time, centerAxis);\n      p5.sphere(40);\n      p5.pop();\n      \n\n      \n      time += 0.03;  // update the time\n      \n    }\n  }",{"ruleId":"78","replacedBy":"79"},{"ruleId":"80","replacedBy":"81"},{"ruleId":"82","severity":1,"message":"83","line":3,"column":8,"nodeType":"84","messageId":"85","endLine":3,"endColumn":16},{"ruleId":"78","replacedBy":"86"},{"ruleId":"80","replacedBy":"87"},{"ruleId":"82","severity":1,"message":"88","line":3,"column":10,"nodeType":"84","messageId":"85","endLine":3,"endColumn":22},{"ruleId":"82","severity":1,"message":"89","line":25,"column":9,"nodeType":"84","messageId":"85","endLine":25,"endColumn":12},{"ruleId":"82","severity":1,"message":"90","line":32,"column":9,"nodeType":"84","messageId":"85","endLine":32,"endColumn":18},{"ruleId":"82","severity":1,"message":"91","line":33,"column":9,"nodeType":"84","messageId":"85","endLine":33,"endColumn":19},{"ruleId":"82","severity":1,"message":"92","line":45,"column":9,"nodeType":"84","messageId":"85","endLine":45,"endColumn":13},"no-native-reassign",["93"],"no-negated-in-lhs",["94"],"no-unused-vars","'Recorder' is defined but never used.","Identifier","unusedVar",["93"],["94"],"'animationOne' is defined but never used.","'img' is assigned a value but never used.","'poolWidth' is assigned a value but never used.","'poolHeight' is assigned a value but never used.","'text' is assigned a value but never used.","no-global-assign","no-unsafe-negation"]